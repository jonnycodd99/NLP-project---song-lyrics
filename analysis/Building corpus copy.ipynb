{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load lyrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for english songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "chunk_size = 100000  # Number of rows per chunk\n",
    "for chunk in pd.read_csv('song_lyrics.csv', chunksize=chunk_size):\n",
    "    # Filter the chunk to keep only rows where language is 'en'\n",
    "    filtered_chunk = chunk[chunk['language'] == 'en']\n",
    "    \n",
    "    # Append the filtered chunk to the full DataFrame\n",
    "    full_df = pd.concat([full_df, filtered_chunk], ignore_index=True)\n",
    "\n",
    "    # Print the current number of rows in the DataFrame\n",
    "    print(f'Number of rows after processing chunk: {len(full_df)}')\n",
    "\n",
    "full_df.to_csv('english songs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jonnycodd/Documents/MASTERS/Text mining/Project/english songs.csv')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display value counts for the 'year' column\n",
    "print(df['year'].value_counts())\n",
    "\n",
    "# Reset display.max_rows to its default (usually 60)\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean artist and title \n",
    "# Replace hyphens with spaces in 'Title' and 'Main_Artist' in 'charts' DataFrame\n",
    "charts['Title'] = charts['Title'].str.replace('-', ' ', regex=False)\n",
    "charts['Main_Artist'] = charts['Main_Artist'].str.replace('-', ' ', regex=False)\n",
    "\n",
    "# Replace hyphens with spaces in 'title' and 'artist' in 'df' DataFrame\n",
    "df['title'] = df['title'].str.replace('-', ' ', regex=False)\n",
    "df['artist'] = df['artist'].str.replace('-', ' ', regex=False)\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    if isinstance(s, str):\n",
    "        return s.translate(str.maketrans('', '', string.punctuation))\n",
    "    else:\n",
    "        # Return as is if not a string (e.g., NaN or numeric)\n",
    "        return s\n",
    "\n",
    "# Clean 'Title' and 'Main_Artist' in 'charts' DataFrame\n",
    "charts['Title'] = charts['Title'].str.lower().map(remove_punctuation).str.strip()\n",
    "charts['Main_Artist'] = charts['Main_Artist'].str.lower().map(remove_punctuation).str.strip()\n",
    "\n",
    "# Clean 'title' and 'artist' in 'df' DataFrame\n",
    "df['title'] = df['title'].str.lower().map(remove_punctuation).str.strip()\n",
    "df['artist'] = df['artist'].str.lower().map(remove_punctuation).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep relevent rows\n",
    "columns_to_keep = ['title', 'tag', 'artist', 'year', 'views', 'features', 'lyrics']\n",
    "\n",
    "# Select only the specified columns from 'df'\n",
    "df = df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['title', 'artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'year': 'release year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep top 4000 songs per year in terms of views\n",
    "top_songs_per_year = df.groupby('release year').apply(lambda x: x.nlargest(4000, 'views')).reset_index(drop=True)\n",
    "top_songs_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_songs_per_year.to_csv('top songs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional functions\n",
    "def strip(word):\n",
    "    mod_string = re.sub(r'\\W+', '', word)\n",
    "    return mod_string\n",
    "\n",
    "#the following leaves in place two or more capital letters in a row\n",
    "#will be ignored when using standard stemming\n",
    "def abbr_or_lower(word):\n",
    "    if re.match('([A-Z]+[a-z]*){2,}', word):\n",
    "        return word\n",
    "    else:\n",
    "        return word.lower()\n",
    "\n",
    "#modular pipeline for stemming, lemmatizing and lowercasing\n",
    "#note this is NOT lemmatizing using grammar pos\n",
    "    \n",
    "def tokenize(text, modulation):\n",
    "    if modulation<2:\n",
    "        tokens = re.split(r'\\W+', text)\n",
    "        stems = []\n",
    "        # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "        for token in tokens:\n",
    "            lowers=abbr_or_lower(token)\n",
    "            if lowers not in stop_words:\n",
    "                if re.search('[a-zA-Z]', lowers):\n",
    "                    if modulation==0:\n",
    "                        stems.append(lowers)\n",
    "                    if modulation==1:\n",
    "                        stems.append(porter.stem(lowers))\n",
    "    else:\n",
    "        sp_text=sp(text)\n",
    "        stems = []\n",
    "        lemmatized_text=[]\n",
    "        for word in sp_text:\n",
    "            lemmatized_text.append(word.lemma_)\n",
    "        stems = [abbr_or_lower(strip(w)) for w in lemmatized_text if (abbr_or_lower(strip(w))) and (abbr_or_lower(strip(w)) not in stop_words)]\n",
    "    return \" \".join(stems)\n",
    "\n",
    "\n",
    "def vectorize(tokens, vocab):\n",
    "    vector=[]\n",
    "    for w in vocab:\n",
    "        vector.append(tokens.count(w))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pre posessing pipleines\n",
    "def preprocess_text_data(corpus_data, mod, column):\n",
    "\n",
    "    text_preproc = corpus_data[column].astype(str).progress_apply(lambda row: tokenize(row, mod))\n",
    "    \n",
    "    corpus_data[column] = text_preproc\n",
    "\n",
    "    corpus_data.dropna(subset=[column], inplace=True)\n",
    "    corpus_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Convert to string\n",
    "    corpus_data[column] = corpus_data[column].astype(str)\n",
    "\n",
    "    return corpus_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a library of stopwords and defining a lemmatizer\n",
    "porter=SnowballStemmer(\"english\")\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = pd.read_csv('/Users/jonnycodd/Documents/MASTERS/Text mining/Project/top songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>release year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>let it be</td>\n",
       "      <td>rock</td>\n",
       "      <td>the beatles</td>\n",
       "      <td>1970</td>\n",
       "      <td>1481859</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Verse 1]\\nWhen I find myself in times of trou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>your song</td>\n",
       "      <td>rock</td>\n",
       "      <td>elton john</td>\n",
       "      <td>1970</td>\n",
       "      <td>1323166</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Verse 1]\\nIt's a little bit funny, this feeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>rock</td>\n",
       "      <td>black sabbath</td>\n",
       "      <td>1970</td>\n",
       "      <td>508767</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\n\\n[Verse 1]\\nFinished with my woman\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>immigrant song</td>\n",
       "      <td>rock</td>\n",
       "      <td>led zeppelin</td>\n",
       "      <td>1970</td>\n",
       "      <td>494355</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]​\\n(2, 3, 4)\\n\\n[Chorus]\\nAhh! Ahh!\\nWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have you ever seen the rain</td>\n",
       "      <td>rock</td>\n",
       "      <td>creedence clearwater revival</td>\n",
       "      <td>1970</td>\n",
       "      <td>468949</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Verse 1]\\nSomeone told me long ago\\nThere's a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191995</th>\n",
       "      <td>attention female perspective</td>\n",
       "      <td>pop</td>\n",
       "      <td>andie case</td>\n",
       "      <td>2017</td>\n",
       "      <td>34129</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Verse 1]\\nI been runnin' 'round, runnin' 'rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191996</th>\n",
       "      <td>​nobody 😔</td>\n",
       "      <td>rap</td>\n",
       "      <td>shinigami</td>\n",
       "      <td>2017</td>\n",
       "      <td>34115</td>\n",
       "      <td>{​shinigami}</td>\n",
       "      <td>[Verse 1]\\nTake me away from this path that I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191997</th>\n",
       "      <td>my time</td>\n",
       "      <td>rap</td>\n",
       "      <td>wolves</td>\n",
       "      <td>2017</td>\n",
       "      <td>34114</td>\n",
       "      <td>{}</td>\n",
       "      <td>I'm ready to play now\\nPut me in the game now\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191998</th>\n",
       "      <td>down in flames</td>\n",
       "      <td>pop</td>\n",
       "      <td>ella vos</td>\n",
       "      <td>2017</td>\n",
       "      <td>34113</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Verse 1]\\nSlippin' off the edge\\nOut of phase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191999</th>\n",
       "      <td>blank 2</td>\n",
       "      <td>rap</td>\n",
       "      <td>jeffy the puppet</td>\n",
       "      <td>2017</td>\n",
       "      <td>34102</td>\n",
       "      <td>{}</td>\n",
       "      <td>Jeffy, The Puppet: Hey daddy, I smack these Ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title   tag                        artist  \\\n",
       "0                          let it be  rock                   the beatles   \n",
       "1                          your song  rock                    elton john   \n",
       "2                           paranoid  rock                 black sabbath   \n",
       "3                     immigrant song  rock                  led zeppelin   \n",
       "4        have you ever seen the rain  rock  creedence clearwater revival   \n",
       "...                              ...   ...                           ...   \n",
       "191995  attention female perspective   pop                    andie case   \n",
       "191996                     ​nobody 😔   rap                     shinigami   \n",
       "191997                       my time   rap                        wolves   \n",
       "191998                down in flames   pop                      ella vos   \n",
       "191999                       blank 2   rap              jeffy the puppet   \n",
       "\n",
       "        release year    views      features  \\\n",
       "0               1970  1481859            {}   \n",
       "1               1970  1323166            {}   \n",
       "2               1970   508767            {}   \n",
       "3               1970   494355            {}   \n",
       "4               1970   468949            {}   \n",
       "...              ...      ...           ...   \n",
       "191995          2017    34129            {}   \n",
       "191996          2017    34115  {​shinigami}   \n",
       "191997          2017    34114            {}   \n",
       "191998          2017    34113            {}   \n",
       "191999          2017    34102            {}   \n",
       "\n",
       "                                                   lyrics  \n",
       "0       [Verse 1]\\nWhen I find myself in times of trou...  \n",
       "1       [Verse 1]\\nIt's a little bit funny, this feeli...  \n",
       "2       [Intro]\\n\\n[Verse 1]\\nFinished with my woman\\n...  \n",
       "3       [Intro]​\\n(2, 3, 4)\\n\\n[Chorus]\\nAhh! Ahh!\\nWe...  \n",
       "4       [Verse 1]\\nSomeone told me long ago\\nThere's a...  \n",
       "...                                                   ...  \n",
       "191995  [Verse 1]\\nI been runnin' 'round, runnin' 'rou...  \n",
       "191996  [Verse 1]\\nTake me away from this path that I ...  \n",
       "191997  I'm ready to play now\\nPut me in the game now\\...  \n",
       "191998  [Verse 1]\\nSlippin' off the edge\\nOut of phase...  \n",
       "191999  Jeffy, The Puppet: Hey daddy, I smack these Ho...  \n",
       "\n",
       "[192000 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean song lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove text inside square brackets\n",
    "lyrics_df['lyrics'] = lyrics_df['lyrics'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "\n",
    "# Replace \\n with a space \n",
    "lyrics_df['lyrics'] = lyrics_df['lyrics'].str.replace('\\n', ' ', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 24836/192000 [12:57<1:44:19, 26.70it/s]"
     ]
    }
   ],
   "source": [
    "lyrics_df = preprocess_text_data(lyrics_df, mod = 2, column = 'lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = lyrics_df.dropna(subset=['lyrics'])\n",
    "lyrics_df.to_csv('../../data/top songs processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
