---
title: "NLP Project - STM"
output: html_notebook
---
```{r}
if (!require(devtools)) install.packages("devtools")
library(devtools)
devtools::install_github("mikajoh/tidystm", dependencies = TRUE)
```

```{r}
library(sf)
library(tidyverse)
library(stm)
library(topicmodels)
library(lda) 
library(quanteda)
library(quanteda.textplots)
library(slam)
library(quanteda)
library(dplyr)
library(ggplot2)
library(tidystm)
library(RColorBrewer)
library(ggthemes)
library(gridExtra)
library(tidytext)
library(patchwork)

# Define the color palette
my_palette <- brewer.pal(9, "Set1")  

# Set directory
DIR <- '.'
```

# Load data

```{r}
# Load data
lyrics_data <- read.csv(file.path(DIR, '../../data/top songs processed.csv'))
```

```{r}
# Remove all 2 letter words 
lyrics_data$lyrics <- gsub("\\b\\w{2}\\b", "", lyrics_data$lyrics)

# Add ID column 
lyrics_data <- lyrics_data %>%
  mutate(row_num = row_number())

# Build corpus
lyricsCorpus <- corpus(lyrics_data, docid_field = 'row_num', text_field = 'lyrics')

# Tokenize corpus
lyricsCorpus_tokenized <- tokens(lyricsCorpus)

#Convert our tokenized corpus into a documentÃ—term frequency
dfm_lyricsCorpus<- dfm(lyricsCorpus_tokenized)
```


# Plot genre per year

```{r}
# Step 1: Calculate total tags per year
yearly_totals <- lyrics_data %>%
  group_by(release.year) %>%
  summarise(total_tags = n(), .groups = 'drop')

# Step 2: Calculate tag counts per year
tag_counts_per_year <- lyrics_data %>%
  group_by(release.year, tag) %>%
  summarise(tag_count = n(), .groups = 'drop')

# Step 3: Join the totals with the counts and calculate percentages
tag_percentages <- tag_counts_per_year %>%
  left_join(yearly_totals, by = "release.year") %>%
  mutate(percentage = (tag_count / total_tags) * 100)

# Step 4: Plot the data
ggplot(tag_percentages, aes(x = release.year, y = percentage, group = tag, color = tag)) +
  geom_line() +
  theme_calc() +
  theme(panel.border = element_blank()) +
  labs(x = "Release Year", y = "Percentage (%)") +
  scale_color_discrete(name = "Genre", labels = c("Country", "Misc", "Pop", "Rap", "R & B", "Rock"))
ggsave("../figures/Genres over time.png", width = 23, height = 15, units = "cm")
```

# Filter corpus

## Attempt 1

```{r}
# Create custom stop words list
custom_list_stopwords <- c(stopwords("en"))

# Filter corpus
dfm_lyricsCorpus_filtered <- tokens(lyricsCorpus, remove_punct = TRUE, 
                                          remove_symbols = TRUE, remove_numbers = TRUE) %>% 
                            tokens_remove(custom_list_stopwords) %>%
                            tokens_wordstem() %>% 
                            tokens_ngrams(n = c(1, 2)) %>% 
                            dfm() %>% 
                            dfm_tolower() %>% 
                            dfm_trim(min_termfreq = 5, min_docfreq = 0.01, max_docfreq = 0.99, docfreq_type = "prop")
```


```{r, warning=FALSE}
textplot_wordcloud(dfm_lyricsCorpus_filtered, random_order = FALSE, rotation = 0.25, 
    color = RColorBrewer::brewer.pal(8, "Dark2"))
```

```{r}
# Calculate the document frequency for each term
# This computes how many documents each term appears in
doc_freqs <- docfreq(dfm_lyricsCorpus_filtered)

# Convert to a data frame, sort it, and create a column for term ID or rank
df_doc_freqs <- data.frame(term = names(doc_freqs), doc_freq = doc_freqs) %>%
  arrange(desc(doc_freq)) %>%
  mutate(term_id = row_number())

# Create the plot for document frequencies
ggplot(df_doc_freqs, aes(x = term_id, y = doc_freq)) +
  geom_bar(stat = "identity") +
  labs(title = "Document Frequency Distribution", x = "Term ID", y = "Document Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) # Hide x-axis text for clarity

```
## Attempt 2
```{r}
# Filter corpus
dfm_lyricsCorpus_filtered <- tokens(lyricsCorpus, remove_punct = TRUE, 
                                          remove_symbols = TRUE, remove_numbers = TRUE) %>% 
                            tokens_remove(custom_list_stopwords) %>%
                            tokens_wordstem() %>% 
                            tokens_ngrams(n = c(1, 2)) %>% 
                            dfm() %>% 
                            dfm_tolower() %>% 
                            dfm_trim(min_termfreq = 5, min_docfreq = 480, max_docfreq = 30000)
```


```{r, warning=FALSE}
textplot_wordcloud(dfm_lyricsCorpus_filtered, random_order = FALSE, rotation = 0.25, 
    color = RColorBrewer::brewer.pal(8, "Dark2"))
```


```{r}
# Calculate the document frequency for each term
# This computes how many documents each term appears in
doc_freqs <- docfreq(dfm_lyricsCorpus_filtered)

# Convert to a data frame, sort it, and create a column for term ID or rank
df_doc_freqs <- data.frame(term = names(doc_freqs), doc_freq = doc_freqs) %>%
  arrange(desc(doc_freq)) %>%
  mutate(term_id = row_number())

# Create the plot for document frequencies
ggplot(df_doc_freqs, aes(x = term_id, y = doc_freq)) +
  geom_bar(stat = "identity") +
  labs(title = "Document Frequency Distribution", x = "Term ID", y = "Document Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) # Hide x-axis text for clarity
```

## Optimise for K

```{r}
# Optimise for K
system.time(
  searchK <- searchK(documents = dfm_lyricsCorpus_filtered, 
                     K = c(10,15, 20, 25, 30,40), #specify K to try
                      N = 4800, # Use 10% of observations to determine optimum number of topics
                     proportion = 0.5, # hold out 50% to use for testing
                     heldout.seed = 1234, 
                     M = 10, # number of random initializations to perform
                     cores = 1, # default
                     prevalence =~ s(date) + genre + s(date)*genre,
                     max.em.its = 75, # Max iterations
                     data = meta_data,
                     init.type = "Spectral",
                     verbose=TRUE)
)
```

```{r}
# Extracting the data from the searchK list
K_values <- searchK$results$K  
heldout_likelihood <- searchK$results$heldout
semcoh <- searchK$results$semcoh
residual<- searchK$results$residual
lowerbound <- searchK$results$lbound

# Creating a data frame for plotting
plot_data <- data.frame(
  K = unlist(K_values),
  HeldOutLikelihood = unlist(heldout_likelihood),
  semcoh = unlist(semcoh),
  residual = unlist(residual),
  lowerbound = unlist(lowerbound)
)

# Held-Out Likelihood Plot
plot_heldout <- ggplot(plot_data, aes(x = K, y = HeldOutLikelihood)) +
  geom_line(color = my_palette[1]) +
  theme_minimal() +
  theme(axis.text.y = element_text(angle = 90)) +
  labs(x = "",
       y = "Held-Out Likelihood")

# Semantic Coherence Plot
plot_semcoh <- ggplot(plot_data, aes(x = K, y = semcoh)) +
  geom_line(color = my_palette[2]) +
  theme_minimal() +
  theme(axis.text.y = element_text(angle = 90)) +
  labs(x = "",
       y = "Semantic Coherence")

# Residual Plot
plot_residual <- ggplot(plot_data, aes(x = K, y = residual)) +
  geom_line(color = my_palette[3]) +
  theme_minimal() +
  theme(axis.text.y = element_text(angle = 90)) +
  labs(x = "Number of Topics (K)",
       y = "Residual")

# Lower Bound Plot
plot_lowerbound <- ggplot(plot_data, aes(x = K, y = lowerbound)) +
  geom_line(color = my_palette[4]) +
  theme_minimal() +
  theme(axis.text.y = element_text(angle = 90)) +
  labs(x = "Number of Topics (K)",
       y = "Lower Bound")

# Combining the graphs into one plot
combined_plot <- grid.arrange(plot_heldout, plot_semcoh, plot_residual, plot_lowerbound, ncol = 2)

# Combining the graphs into one plot
combined_plot <- grid.arrange(plot_heldout, plot_semcoh, plot_residual, plot_lowerbound, ncol = 2)
ggsave("../figures/Model diagnostics.png", width = 23, height = 15, units = "cm")
```

# Run STM

```{r}
# Assuming dfm_lyricsCorpus_filtered is your document-term matrix
non_empty_docs <- which(rowSums(dfm_lyricsCorpus_filtered) > 0)

# Filter your DFM to keep only non-empty documents
dfm_lyricsCorpus_filtered <- dfm_lyricsCorpus_filtered[non_empty_docs, ]

# Prepare the metadata for STM
meta_data <- data.frame(date = lyrics_data$release.year, genre = lyrics_data$tag)
meta_data <- meta_data[non_empty_docs, ]
```

```{r}
# Run the STM model
stm_model <- stm(documents = dfm_lyricsCorpus_filtered, 
                 data = meta_data, 
                 K = 20, 
                 prevalence = ~ s(date) + genre + s(date)*genre, 
                 seed = 123, init.type = "Spectral")
```

# Analysis
## Overall topic proportions

```{r}
topic_labels <- c("Vocal Expressions", "Love", "Feelings and Friendship", "Conversational and Family", 
               "Journey", "Dark Imagery", "Aspiration", "Party", "Male Terms", "Change and Departure",
               "Desire", "Expletives", "Reflection", "Spirituality", "Sociopolitical", "Romance",
               "Street Life and Expletives", "Tonight", "Exclamations", "Knowledge")
```

```{r}
# Plot topic proportions
td_gamma <- tidy(stm_model, matrix = "gamma",
                 document_names = rownames(dfm_lyricsCorpus_filtered))
td_beta <- tidy(stm_model)


top_terms <- td_beta %>%
  arrange(beta) %>%
  group_by(topic) %>%
  top_n(7, beta) %>%
  arrange(-beta) %>%
  select(topic, term) %>%
  summarise(terms = list(term)) %>%
  mutate(terms = map(terms, paste, collapse = ", ")) %>% 
  unnest()
new_names <- c("Vocal Expressions", "Love", "Feelings and Friendship", "Conversational and Family", 
               "Journey", "Dark Imagery", "Aspiration", "Party", "Male Terms", "Change and Departure",
               "Desire", "Expletives", "Reflection", "Spirituality", "Sociopolitical", "Romance",
               "Street Life and Expletives", "Tonight", "Exclamations", "Knowledge")

top_terms$topic_label <- new_names

gamma_terms <- td_gamma %>%
  group_by(topic) %>%
  summarise(gamma = mean(gamma)) %>%
  arrange(desc(gamma)) %>%
  left_join(top_terms, by = "topic") %>%
  mutate(topic = paste0("Topic ", topic),
         topic = reorder(topic, gamma))

gamma_terms %>%
  top_n(20, gamma) %>%
  mutate(topic_label = factor(topic_label, levels = rev(unique(topic_label)))) %>%
  ggplot(aes(topic_label, gamma, label = terms, fill = topic_label)) +
  geom_col(show.legend = FALSE) +
  geom_text(hjust = 0, nudge_y = 0.0005, size = 3) +
  coord_flip() +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0, 0.22)) +
  theme_calc() +
  theme(plot.title = element_text(size = 16),
        plot.subtitle = element_text(size = 13),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  labs(x = NULL, y = expression("Expected Topic Proportions"))
ggsave("../figures/Topic proportions.png", width = 23, height = 15, units = "cm")
```

```{r}
labelTopics(stm_model, n = 7)
```

## Topics over time

```{r}
# Estimate time effect
time_effect <- estimateEffect(1:20 ~ s(date), stm_model, meta = meta_data, uncertainty = "Global")
effect <- extract.estimateEffect(time_effect, "date", model = stm_model, method = "pointestimate")

# Add topic labels
effect <- effect %>%
  mutate(topic_label = topic_labels[topic])

# Add overall topic proportions
gamma_terms_subset <- gamma_terms[, c("topic_label", "gamma")]
effect <- merge(effect, gamma_terms_subset , by = "topic_label", all.x = TRUE)
```

```{r}
# All topics over time
topics_data <- effect  
topics_data <- topics_data %>% arrange(desc(gamma))
topics_data$topic_label <- factor(topics_data$topic_label, levels = unique(topics_data$topic_label))

ggplot(topics_data, aes(x = covariate.value, y = estimate, group = topic, color = as.factor(topic))) +
  geom_line() +
  geom_line(aes(y = ci.lower), linetype = "dashed") +  
  geom_line(aes(y = ci.upper), linetype = "dashed") +
  theme_calc() +
  theme(legend.position = "none",
        strip.text.x = element_text(size = 14, face = "bold")) +  # Adjust strip text size and make it bold
  labs(x = "Release Year", y = "Expected Topic Proportions", color = "Topic") +
  facet_wrap(~ topic_label, ncol = 5)

```

## Network 

```{r}
# extract network
devtools::install_github('cschwem2er/stminsights')
library(stminsights)
library(ggraph)
library(tidygraph)
library(quanteda)
library(igraph)

stm_corrs <- get_network(model = stm_model,
                         method = 'simple',
                         labels = topic_labels,
                         cutoff = 0.001,
                         cutiso = TRUE)


# Ensure edge weights are positive and non-NA
E(stm_corrs)$weight <- ifelse(E(stm_corrs)$weight <= 0 | is.na(E(stm_corrs)$weight), 0.1, E(stm_corrs)$weight)

sorted_gamma_terms <- gamma_terms %>%
  mutate(topic_number = as.numeric(str_extract(topic, "\\d+"))) %>%
  arrange(topic_number) %>%
  select(-topic_number)  # Remove the auxiliary column after sorting

V(stm_corrs)$proportion <- sorted_gamma_terms$gamma

my_graph <- ggraph(stm_corrs, layout = "fr") +
  geom_edge_link(aes(edge_alpha = weight), show.legend = FALSE) +
  geom_node_point(aes(size = proportion, color = as.factor(name)), show.legend = FALSE) + # Node size based on topic proportion
 geom_node_text(aes(label = name), repel = TRUE, check_overlap = TRUE, vjust = 1, hjust = 1, fontface = "bold") +  # Make text bold
  scale_size(range = c(1, 10)) + # Adjust size scale as needed
  theme_graph() 
my_graph
ggsave("../figures/network graph.png", plot = my_graph, width = 10, height = 8, dpi = 300)
```
## Genre Graph

```{r}
genre_effect <- estimateEffect(1:20 ~ genre, stm_model, meta = meta_data, uncertainty = "Global")
effect <- extract.estimateEffect(genre_effect, "genre", model = stm_model, method = "pointestimate")

effect <- effect %>%
  mutate(topic_label = topic_labels[topic])

effect_filtered <- effect %>%
  filter(covariate.value != "misc")

ggplot(effect_filtered, aes(x = covariate.value, y = estimate, fill = as.factor(covariate.value))) +
  geom_col() +
  theme_minimal() +  
    theme(
    #legend.position = "none",
    axis.title = element_text(size = 8), # Decrease font size for axis titles
    axis.text = element_blank(), # Decrease font size for axis text (ticks)
    strip.text = element_text(size = 7) # Decrease font size for facet titles
  ) +
  labs(x = "Genre", y = "Expected Topic Proportions", fill = "Topic") +
  facet_wrap(~ topic_label, ncol = 5) 

```


### genre x time

```{r}
meta_data$genre <- as.factor(meta_data$genre)
meta_data$date <- as.numeric(meta_data$date)

# Estimate genre*time effect
time_genre_interaction_effect <- estimateEffect(~ genre * s(date), stm_model, meta = meta_data, uncertainty = "Global")

effect <- lapply(unique(meta_data$genre), function(i) {
  extract.estimateEffect(x = time_genre_interaction_effect,
                         covariate = "date",
                         method = "pointestimate",
                         model = stm_model,
                         labeltype = "Highest",
                         n = 4,
                         moderator = "genre",
                         moderator.value = i)
})

rock_df <- effect[[1]]
rock_df <- rock_df %>%
  mutate(topic_label = topic_labels[topic])

rb_df <- effect[[2]]
rb_df <- rb_df %>%
  mutate(topic_label = topic_labels[topic])

pop_df <- effect[[3]]
pop_df <- pop_df %>%
  mutate(topic_label = topic_labels[topic])

misc_df <- effect[[4]]
misc_df <- misc_df %>%
  mutate(topic_label = topic_labels[topic])

rap_df <- effect[[5]]
rap_df <- rap_df %>%
  mutate(topic_label = topic_labels[topic])

country_df <- effect[[6]]
country_df<- country_df %>%
  mutate(topic_label = topic_labels[topic])
```



```{r}
# First, calculate the average effect for each topic
#rock
average_gamma_rock <- rock_df %>%
  group_by(topic) %>%
  summarise(avg_gamma = mean(estimate, na.rm = TRUE)) %>%
  arrange(desc(avg_gamma)) %>%
  slice(1:5)

# Then, filter ydataframe to only include these top 5 topics
rock_df_filtered <- rock_df %>%
  filter(topic %in% average_gamma_rock$topic)

#rb
average_gamma_rb <- rb_df %>%
  group_by(topic) %>%
  summarise(avg_gamma = mean(estimate, na.rm = TRUE)) %>%
  arrange(desc(avg_gamma))  %>%
  slice(1:5)

# Then, filter  dataframe to only include these top 5 topics
rb_df_filtered <- rb_df %>%
  filter(topic %in% average_gamma_rb$topic) 


#pop
average_gamma_pop <- pop_df %>%
  group_by(topic) %>%
  summarise(avg_gamma = mean(estimate, na.rm = TRUE)) %>%
  arrange(desc(avg_gamma)) %>%
  slice(1:5) # Select the top 5 topics based on average gamma

# Then, filter dataframe to only include these top 5 topics
pop_df_filtered <- pop_df %>%
  filter(topic %in% average_gamma_pop$topic)

#rap
average_gamma_rap <- rap_df %>%
  group_by(topic) %>%
  summarise(avg_gamma = mean(estimate, na.rm = TRUE)) %>%
  arrange(desc(avg_gamma)) %>%
  slice(1:5) # Select the top 5 topics based on average gamma

# Then, filter dataframe to only include these top 5 topics
rap_df_filtered <- rap_df %>%
  filter(topic %in% average_gamma_rap$topic)

#country
average_gamma_country <- country_df %>%
  group_by(topic) %>%
  summarise(avg_gamma = mean(estimate, na.rm = TRUE)) %>%
  arrange(desc(avg_gamma)) %>%
  slice(1:5) # Select the top 5 topics based on average gamma

# Then, filter dataframe to only include these top 5 topics
country_df_filtered <- country_df %>%
  filter(topic %in% average_gamma_country$topic)
```


```{r}
rock_plot <- ggplot(rock_df_filtered, aes(x = covariate.value, y = estimate, group = topic_label, color = as.factor(topic_label))) +
  geom_line() +
  theme_minimal() + 
  theme(legend.position = "right",
        plot.title = element_text(hjust = 0.5),
        legend.text = element_text(size = 8)) + # Adjust legend text size here
  labs(title = "Rock", x = "Release Year", y = "Expected Topic Proportions", color = "Topic")

print(rock_plot)

# Save the plot with adjusted width and height for a wider image
ggsave("rock_plot.png", rock_plot, width = 30, height = 15, units = "cm")
```


```{r}
rb_plot <- ggplot(rb_df_filtered, aes(x = covariate.value, y = estimate, group = topic_label, color = as.factor(topic_label))) +
  geom_line() +
  theme_minimal() + # Assuming theme_calc() was a typo; using theme_minimal() instead
 theme(legend.position = "right",
        plot.title = element_text(hjust = 0.5)) + # Center the title
  labs(title = "R&B", x = "Release Year", y = "Expected Topic Proportions", color = "Topic")

print(rb_plot)

ggsave("rb_plot.png", rb_plot, width = 20, height = 15, units = "cm")
```

```{r}
pop_plot <- ggplot(pop_df_filtered, aes(x = covariate.value, y = estimate, group = topic_label, color = as.factor(topic_label))) +
  geom_line() +
  theme_minimal() + # Assuming theme_calc() was a typo; using theme_minimal() instead
 theme(legend.position = "right",
        plot.title = element_text(hjust = 0.5)) + # Center the title
  labs(title = "Pop", x = "Release Year", y = "Expected Topic Proportions", color = "Topic")

print(pop_plot)

ggsave("pop_plot.png", rb_plot, width = 20, height = 20, units = "cm")
```

```{r}
rap_plot <- ggplot(rap_df_filtered, aes(x = covariate.value, y = estimate, group = topic_label, color = as.factor(topic_label))) +
  geom_line() +
  theme_minimal() + # Assuming theme_calc() was a typo; using theme_minimal() instead
 theme(legend.position = "right",
        plot.title = element_text(hjust = 0.5)) + # Center the title
  labs(title = "Rap", x = "Release Year", y = "Expected Topic Proportions", color = "Topic")

print(rap_plot)

ggsave("rap_plot.png", rb_plot, width = 20, height = 20, units = "cm")
```

```{r}
country_plot <- ggplot(country_df_filtered, aes(x = covariate.value, y = estimate, group = topic_label, color = as.factor(topic_label))) +
  geom_line() +
  theme_minimal() + # Assuming theme_calc() was a typo; using theme_minimal() instead
 theme(legend.position = "right",
        plot.title = element_text(hjust = 0.5)) + # Center the title
  labs(title = "Country", x = "Release Year", y = "Expected Topic Proportions", color = "Topic")

print(country_plot)

ggsave("country_plot.png", rb_plot, width = 20, height = 20, units = "cm")
```

